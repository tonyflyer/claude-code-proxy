# Required API Keys
ANTHROPIC_API_KEY="your-anthropic-api-key" # Needed if proxying *to* Anthropic
OPENAI_API_KEY="sk-..."
GEMINI_API_KEY="your-google-ai-studio-key"

# Optional: Provider Preference and Model Mapping
# Controls which provider (google, openai, or anthropic) is preferred for mapping haiku/sonnet.
# Defaults to openai if not set.
# Set to "anthropic" for "just an Anthropic proxy" mode (no remapping)
PREFERRED_PROVIDER="openai"
OPENAI_BASE_URL="https://api.openai.com/v1"

# Optional: Specify the exact models to map haiku/sonnet to.
# If PREFERRED_PROVIDER=google, these MUST be valid Gemini model names known to the server.
# Defaults to gemini-2.5-pro and gemini-2.5-flash if PREFERRED_PROVIDER=google.
# Defaults to gpt-4.1 and gpt-4.1-mini if PREFERRED_PROVIDER=openai.
# These are IGNORED when PREFERRED_PROVIDER=anthropic (models are not remapped).
# BIG_MODEL="gpt-4.1"
# SMALL_MODEL="gpt-4.1-mini"

# Example Google mapping:
# PREFERRED_PROVIDER="google"
# BIG_MODEL="gemini-2.5-pro"
# SMALL_MODEL="gemini-2.5-flash"

# Example Google with vertex AI auth via ADC:
# PREFERRED_PROVIDER="google"
# USE_VERTEX_AUTH=true
# BIG_MODEL="gemini-2.5-pro"
# SMALL_MODEL="gemini-2.5-flash"

# Example "just an Anthropic proxy" mode:
# PREFERRED_PROVIDER="anthropic"
# (BIG_MODEL and SMALL_MODEL are ignored in this mode)

# Example Local Ollama:
# Ollama 默认地址: http://localhost:11434/v1
# Ollama 官方文档: https://ollama.com/
# 1. 安装 Ollama: curl -fsSL https://ollama.ai/install.sh | sh
# 2. 拉取模型: ollama pull qwen3-coder:latest
# 3. 启动服务: ollama serve
# 注意: 运行代理前需要取消系统代理设置，否则请求会失败
#     unset HTTP_PROXY HTTPS_PROXY && export NO_PROXY="*"
# OPENAI_API_KEY="any"  # Ollama 不需要真实 API Key
# PREFERRED_PROVIDER="openai"
# OPENAI_BASE_URL="http://localhost:11434/v1"
# BIG_MODEL="openai/qwen3-coder"  # 使用 openai/ 前缀
# SMALL_MODEL="openai/qwen3-coder"

# Example Local LMStudio:
# LMStudio 默认地址: http://localhost:11435/v1
# LMStudio 官方地址: https://lmstudio.ai/
# 1. 下载安装 LMStudio
# 2. 下载模型并加载
# 3. 启动本地服务器 (Settings -> Developer -> Enable Local Server)
# 注意: 运行代理前需要取消系统代理设置，否则请求会失败
#     unset HTTP_PROXY HTTPS_PROXY && export NO_PROXY="*"
# OPENAI_API_KEY="any"  # LMStudio 不需要真实 API Key
# PREFERRED_PROVIDER="openai"
# OPENAI_BASE_URL="http://localhost:11435/v1"
# BIG_MODEL="openai/qwen/qwen3-8b"  # 使用 openai/ 前缀
# SMALL_MODEL="openai/qwen/qwen3-8b"
